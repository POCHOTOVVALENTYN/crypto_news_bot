# services/ai_summary.py
import os
import logging
import json
import re
import google.generativeai as genai
import asyncio
from typing import Optional, Dict

from openai import AsyncOpenAI
from config import OPENAI_API_KEY, GEMINI_API_KEY

logger = logging.getLogger(__name__)


class NewsAnalyzer:
    def __init__(self):
        self.model = None
        self.openai_client = None

        # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI (Fallback)
        if OPENAI_API_KEY:
            self.openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)

        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Gemini (–û—Å–Ω–æ–≤–Ω–æ–π)
        if GEMINI_API_KEY:
            try:
                genai.configure(api_key=GEMINI_API_KEY)
                self.model = self._find_best_model()
            except Exception as e:
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Gemini: {e}")
        else:
            logger.warning("‚ö†Ô∏è GEMINI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")

    def _find_best_model(self):
        """–ò—â–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ API"""
        try:
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π —Å–ø–∏—Å–æ–∫ (—Å–≤–µ–∂–∏–µ –∏ –±—ã—Å—Ç—Ä—ã–µ –º–æ–¥–µ–ª–∏)
            preferred_models = [
                'gemini-2.0-flash',  # –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–∞ 2.0
                'gemini-1.5-flash',
                'gemini-1.5-flash-002',
                'gemini-1.5-pro',
            ]

            available_models = []
            for m in genai.list_models():
                if 'generateContent' in m.supported_generation_methods:
                    name = m.name.replace('models/', '')
                    available_models.append(name)

            logger.info(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ API: {available_models}")

            # –ò—â–µ–º –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            selected_name = None
            for pref in preferred_models:
                # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ –∏–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                matches = [m for m in available_models if pref in m]
                if matches:
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ —Å–∞–º—É—é –∫–æ—Ä–æ—Ç–∫—É—é (—Ç–æ—á–Ω—É—é) –≤–µ—Ä—Å–∏—é, –∏–ª–∏ –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é
                    selected_name = matches[0]
                    break

            # Fallback: –±–µ—Ä–µ–º –ª—é–±—É—é —Ñ–ª–µ—à –∏–ª–∏ –ø—Ä–æ
            if not selected_name:
                fallback = [m for m in available_models if 'flash' in m or 'pro' in m]
                if fallback:
                    selected_name = fallback[0]

            if selected_name:
                model = genai.GenerativeModel(selected_name)
                logger.info(f"‚úÖ –ò–ò –ê–Ω–∞–ª–∏—Ç–∏–∫ –ø–æ–¥–∫–ª—é—á–µ–Ω –∫: {selected_name}")
                return model

            logger.error("‚ùå –ü–æ–¥—Ö–æ–¥—è—â–∞—è –º–æ–¥–µ–ª—å Gemini –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {e}")
            return None

    def _clean_json_response(self, text: str) -> Optional[Dict]:
        """–û—á–∏—â–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç Markdown –∏ –∏—â–µ—Ç JSON –æ–±—ä–µ–∫—Ç"""
        try:
            # 1. –£–¥–∞–ª—è–µ–º –±–ª–æ–∫–∏ –∫–æ–¥–∞ ```json ... ```
            text = text.replace('```json', '').replace('```', '')

            # 2. –ò—â–µ–º JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –ø–æ–º–æ—â—å—é regex (–æ—Ç –ø–µ—Ä–≤–æ–π { –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π })
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                json_str = match.group(0)
                return json.loads(json_str)

            # 3. –ï—Å–ª–∏ regex –Ω–µ –Ω–∞—à–µ–ª, –ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –≤–µ—Å—å —Ç–µ–∫—Å—Ç
            return json.loads(text.strip())
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}. –¢–µ–∫—Å—Ç: {text[:50]}...")
            return None

    async def _analyze_with_openai(self, prompt: str) -> Optional[Dict]:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ OpenAI"""
        if not self.openai_client:
            logger.error("‚ùå OpenAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –Ω–æ –±—ã–ª –≤—ã–∑–≤–∞–Ω –∫–∞–∫ fallback")
            return None

        try:
            logger.info("ü§ñ –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ OpenAI (Fallback)...")
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini",  # –î–µ—à–µ–≤–∞—è –∏ —É–º–Ω–∞—è –º–æ–¥–µ–ª—å
                messages=[
                    {"role": "system", "content": "You are a crypto news editor. Output only valid JSON."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},  # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç JSON
                timeout=15
            )
            content = response.choices[0].message.content
            return json.loads(content)
        except Exception as e:
            logger.error(f"‚ùå OpenAI Error: {e}")
            return None

    async def analyze_text(self, text: str, context: str = "news") -> Optional[Dict]:
        """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ —Å Fallback"""

        prompt = f"""–¢—ã —Ä–µ–¥–∞–∫—Ç–æ—Ä –∫—Ä–∏–ø—Ç–æ-–Ω–æ–≤–æ—Å—Ç–µ–π.
–ó–ê–î–ê–ß–ê: –°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º.

–í–•–û–î–ù–û–ô –¢–ï–ö–°–¢: "{text}"

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –ó–∞–≥–æ–ª–æ–≤–æ–∫: –¶–µ–ø–ª—è—é—â–∏–π, –ø—Ä–∞–≤–¥–∏–≤—ã–π (–¥–æ 10 —Å–ª–æ–≤).
2. –¢–µ–∫—Å—Ç: 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –¢–æ–ª—å–∫–æ —Å—É—Ç—å.
3. –í–∞–∂–Ω–æ—Å—Ç—å: High –∏–ª–∏ Low.
4. –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: Bullish üü¢ / Bearish üî¥ / Neutral ‚ö™.
5. –ú–æ–Ω–µ—Ç–∞: –¢–∏–∫–µ—Ä (BTC, ETH) –∏–ª–∏ Market.

–í–ê–ñ–ù–û: –û–¢–í–ï–¢ –¢–û–õ–¨–ö–û –í –§–û–†–ú–ê–¢–ï JSON. –ë–ï–ó MARKDOWN.
{{
    "ru_title": "...",
    "ru_summary": "...",
    "importance": "High",
    "coin": "BTC",
    "sentiment": "Bullish"
}}"""

        # 1. –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ Gemini
        if self.model:
            try:
                response = await asyncio.wait_for(
                    asyncio.to_thread(self.model.generate_content, prompt),
                    timeout=20.0
                )

                if response.parts:
                    result = self._clean_json_response(response.text)
                    if result: return result
                    logger.warning("‚ö†Ô∏è Gemini –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON")
                else:
                    logger.warning("‚ö†Ô∏è Gemini –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")

            except Exception as e:
                logger.error(f"‚ùå Gemini Error: {e}")

        # 2. –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ OpenAI (–µ—Å–ª–∏ Gemini —É–ø–∞–ª –∏–ª–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)
        if self.openai_client:
            return await self._analyze_with_openai(prompt)

        return None

    async def process_incoming_news(self, raw_text: str) -> Optional[Dict]:
        """–î–ª—è Telegram Listener"""
        result = await self.analyze_text(raw_text)
        if result and result.get('importance') == 'High':
            return result
        return None

    async def translate_and_analyze(self, title: str, summary: str) -> Optional[Dict]:
        """–î–ª—è RSS"""
        text = f"{title}. {summary}"
        result = await self.analyze_text(text)

        if result:
            return {
                "clean_title": result.get('ru_title', title),
                "clean_summary": result.get('ru_summary', summary),
                "coin": result.get('coin'),
                "sentiment": result.get('sentiment')
            }
        return None